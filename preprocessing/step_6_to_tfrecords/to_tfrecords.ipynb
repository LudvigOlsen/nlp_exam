{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FOLD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_UPSAMPLED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user = \"x\"\n",
    "if user == \"x\":\n",
    "    dpath = \"\"\n",
    "\n",
    "if IS_UPSAMPLED:\n",
    "    pref = \"upsampled_\"\n",
    "else:\n",
    "    pref = \"\"\n",
    "\n",
    "data = pd.read_csv(dpath + pref + \"grouped_for_tf.csv\")\n",
    "train_save_path = dpath + pref + \"train_fold_\" + str(TEST_FOLD) + \".tfrecord\"\n",
    "test_save_path = dpath + pref + \"test_fold_\" + str(TEST_FOLD) + \".tfrecord\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_partition = data[data.Fold == TEST_FOLD].sample(frac=1).reset_index(drop=True)\n",
    "train_partition = data[data.Fold != TEST_FOLD].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(split_id, sentence, label):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "    feature = {\n",
    "      'idx': _int64_feature(split_id),\n",
    "      'sentence': _bytes_feature(sentence),\n",
    "      'label': _int64_feature(label)\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_example = serialize_example(3, b\"han er en klar kat\", 2)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_proto = tf.train.Example.FromString(serialized_example)\n",
    "example_proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(split_id, sentence, label):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        (split_id, sentence, label),  # pass these args to the above function.\n",
    "        tf.string)      # the return type is `tf.string`.\n",
    "    return tf.reshape(tf_string, ()) # The result is a scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(split_id, sentences, labels):\n",
    "    features_dataset = tf.data.Dataset.from_tensor_slices((split_id, sentences, labels))\n",
    "    serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
    "    return serialized_features_dataset\n",
    "\n",
    "\n",
    "def write_tf_records(dat, filename = 'test.tfrecord'):\n",
    "    \"\"\"\n",
    "    dat: serialized_features_dataset\n",
    "    \"\"\"\n",
    "    writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "    writer.write(dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test_partition[\"Diagnosis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not currently used\n",
    "label_map = {\"Control\":0,\n",
    "             \"Depression\":1,\n",
    "             \"Schizophrenia\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "def from_df_to_tfdata(df):\n",
    "    sentences = [str(t) for t in df[\"Transcript.Split\"]]\n",
    "    splt_ids = [int(i) for i in df[\"Split.ID\"]]\n",
    "    labs = [label_map[d] for d in df[\"Diagnosis\"]]\n",
    "\n",
    "    tf_data = create_tf_dataset(split_id = splt_ids,\n",
    "                                sentences = sentences,\n",
    "                                labels = labs)\n",
    "    return tf_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_data = from_df_to_tfdata(test_partition)\n",
    "tf_train_data = from_df_to_tfdata(train_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tf_records(tf_test_data, test_save_path)\n",
    "write_tf_records(tf_train_data, train_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
